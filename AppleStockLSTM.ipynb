{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from datetime import datetime\n\nimport numpy as np\n\nfilename = '../input/apple201718/AAPL.csv'\n\nget_date = lambda x: datetime.strptime(x.decode(\"utf-8\"), '%Y-%m-%d %H:%M')\ndata = np.genfromtxt(filename, names=True, delimiter=',', dtype=None, converters = {0: get_date})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"prices = data[['Open', 'High', 'Low', 'Close', 'Volume']]\ndates = data[['Date']]\nprices = np.array([list(price) for price in prices[['Open', 'High', 'Low', 'Close', 'Volume']]])\ndates = np.array([item for sublist in dates[['Date']] for item in sublist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove rows with nan values\ncount = np.argwhere(np.isnan(prices))\ncount = np.unique(count)\n\ndates = np.delete(dates, count)\nprices = np.delete(prices, count, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale train and test data\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef scale_data(scaler: MinMaxScaler, data: np.array, window=250):\n    length = len(data)\n    iterations = 0\n    for i in range(0, length, window):\n        data[i:i+window,:] = scaler.fit_transform(data[i:i+window,:])\n    return data\n\nscaler = MinMaxScaler(feature_range=(0,1))\nprint(prices[0:5])\nprices = scale_data(scaler, prices)\nprint(prices[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\ndef ewma(data, alpha=0.1, window=10):\n    \"\"\"Compute exponentially weighted moving average for input array.\"\"\"\n    length = len(data)\n    weights = (1 - alpha) ** np.arange(window)\n    weights /= weights.sum()\n    data = np.convolve(data, weights)\n    return data[:length]\n\n\nopen_ewma_v1 = ewma(prices[:,0])\nopen_ewma_v2 = ewma(prices[:,0], 0.01, 5)\nopen_ewma_v3 = ewma(prices[:,0], 0.1, 5)\n\n\n# Plot EWMA and Actual opening price\nplt.figure(figsize=(12,6))\nplt.plot(range(100), prices[0:100, 0], color='darkblue', label='Actual Open')\nplt.plot(range(100), open_ewma_v1[0:100], color='orange', label='EWMA 10WAL0.01 Open')\nplt.plot(range(100), open_ewma_v2[0:100], color='red', label='EWMA 5WAL0.01 Open')\nplt.plot(range(100), open_ewma_v3[0:100], color='green', label='EWMA 5WAL0.1 Open')\nplt.xlabel('Trading Minute')\nplt.ylabel('Scaled Price')\nplt.legend(fontsize=14)\nplt.savefig('EWMA vs Actual V2')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = prices[:,3] # y = scaled close prices\nprint(prices[10:20])\nprices = np.array([ewma(prices[:,i], 0.1, 5) for i in range(prices.shape[1])]).transpose()\nprint(prices[10:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get dates after first 5 days to account for EWMA delay\ndates = dates[5:len(dates)]\nprices = prices[5:len(prices)]\nprint(f\"Rows in prices: {len(prices)}\")\nprint(f\"Rows in dates: {len(dates)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(X: np.array, Y: np.array, window=200):\n    length = len(X)\n    x_out, y_out = [], []\n    for i in range(window, length-1):\n        x_out.append(X[i-window:i,:])\n        y_out.append(Y[i])\n    return np.array(x_out), np.array(y_out)\n\ny = prices[1:len(prices),3] # Set y to Close prices of next minute\nX = prices[0:len(prices)-1,:] # offset date by 1 to predict next output\nX, y = create_dataset(X, y, 250)\nprint(f\"Shape of y: {y.shape}\")\nprint(f\"Shape of X: {X.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data\nsplit = int(0.8*len(X))\nX_train, X_test = X[0:split,:,:], X[split:len(X),:,:]\ny_train, y_test = y[0:split], y[split:len(y)]\nprint(f\"shape of X_train: {X_train.shape}\")\nprint(f\"shape of X_test: {X_test.shape}\")\nprint(f\"shape of y_train: {y_train.shape}\")\nprint(f\"shape of y_test: {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\n\ndef LSTMModel(window: int, n_features: int):\n    \"\"\"Create keras model for LSTM with 3-layers.\"\"\"\n    model = Sequential()\n    model.add(LSTM(25, input_shape=(window, n_features), dropout=0.1,\n                   recurrent_dropout=0.1, return_sequences=True))\n    model.add(LSTM(50, dropout=0.1, recurrent_dropout=0.1, return_sequences=True))\n    model.add(LSTM(25, dropout=0.1, recurrent_dropout=0.1))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mae', optimizer='adam')\n    return model\n\nmodel = LSTMModel(X_train.shape[1], X_train.shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run with GPU\nimport tensorflow as tf\n\nwith tf.device('/GPU:0'):\n    model.fit(X_train, y_train, epochs=10, batch_size=64)\n    model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"LSTM3L10E.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"LSTM3L10E.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\njson_file = open('LSTM3L10E.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\nloaded_model.load_weights('LSTM3L10E.h5')\n\npredictions = loaded_model.predict(X_test)\nscaled_MSE = mean_squared_error(y_test, prediction)\nprint(f\"Scaled MSE for 3-layer LSTM = {scaled_MSE}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nprediction = model.predict(X_test)\nscaled_MSE = mean_squared_error(y_test, prediction)\nprint(f\"Scaled MSE for 3-layer LSTM = {scaled_MSE}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LSTMModelV2(window: int, n_features: int):\n    \"\"\"Create LSTM model with 2 layers.\"\"\"\n    model = Sequential()\n    model.add(LSTM(15, input_shape=(window, n_features), dropout=0.1,\n                   recurrent_dropout=0.2, return_sequences=True))\n    model.add(LSTM(25, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mae', optimizer='adam')\n    return model\n\ndef LSTMModelV3(window: int, n_features: int):\n    \"\"\"Create LSTM model with 4 layers.\"\"\"\n    model = Sequential()\n    model.add(LSTM(10, input_shape=(window, n_features), dropout=0.1,\n               recurrent_dropout=0.1, return_sequences=True))\n    model.add(LSTM(20, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n    model.add(LSTM(15, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n    model.add(LSTM(10, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mae', optimizer='adam')\n\n\nmodel_v2 = LSTMModelV2(X_train.shape[1], X_train.shape[2])\nwith tf.device('/GPU:0'):\n    model.fit(X_train, y_train, epochs=10, batch_size=64)\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_v2 = model_v2.predict(X_test)\nscaled_MSE = mean_squared_error(y_test, prediction_v2)\nprint(f\"Scaled MSE for 2-layer LSTM = {scaled_MSE}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model_v2.to_json()\nwith open(\"LSTM2L10E.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"LSTM2L10E.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v3 = LSTMModelV3(X_train.shape[1], X_train.shape[2])\nwith tf.device('/GPU:0'):\n    model.fit(X_train, y_train, epochs=10, batch_size=64)\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_v3 = model_v3.predict(X_test)\nscaled_MSE = mean_squared_error(y_test, prediction_v3)\nprint(f\"Scaled MSE for 4-layer LSTM = {scaled_MSE}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model_v3.to_json()\nwith open(\"LSTM4L10E.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"LSTM4L10E.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}